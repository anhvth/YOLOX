{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cc286a-49ea-4049-916f-f77330296570",
   "metadata": {},
   "source": [
    "# Convert CVAT Image annotation to coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b824f34-635d-4fda-8436-1d91fac3a595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-xml2dict\n",
      "  Downloading python-xml2dict-0.1.1.tar.gz (2.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: python-xml2dict\n",
      "  Building wheel for python-xml2dict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-xml2dict: filename=python_xml2dict-0.1.1-py3-none-any.whl size=2236 sha256=10c93286918e2e794ca4a732a1b40f84c5848537f3b865761c171d897aee5627\n",
      "  Stored in directory: /home/anhvth8/.cache/pip/wheels/fb/72/4a/f22da03f1c385b59cfc5d1baa5b31d1453e3e5b7ca1fdef5e7\n",
      "Successfully built python-xml2dict\n",
      "Installing collected packages: python-xml2dict\n",
      "Successfully installed python-xml2dict-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-xml2dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb12656-6e97-4670-9a00-06529bbb62ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from avcv.all import *\n",
    "from fastcore.all import *\n",
    "import xml2dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_unique_name(row):\n",
    "    columns = ['@xtl', '@ytl', '@xbr','@ybr', '@label', '@task_id']\n",
    "    return '_'.join([row[c] for c in columns])\n",
    "\n",
    "def load_track_xml2df(path):\n",
    "    d_image = xml2dict.parse(open(path))['annotations']\n",
    "    data_bboxes = []\n",
    "    for track in d_track['track']:\n",
    "        track_data = {k:track[k] for k in ['@id', '@label', '@task_id']}\n",
    "        if isinstance(track['box'], dict):\n",
    "            bboxes = [track['box']]\n",
    "        elif isinstance(track['box'], list):\n",
    "            bboxes = track['box']\n",
    "        else:\n",
    "            import ipdb; ipdb.set_trace()\n",
    "        for bbox in bboxes:\n",
    "            bbox = bbox.copy()\n",
    "            bbox.update(track_data)\n",
    "            if bbox['@outside'] == '0':\n",
    "                data_bboxes.append(bbox)\n",
    "    df_track = pd.DataFrame(data_bboxes)\n",
    "    return df_track\n",
    "\n",
    "def load_image_xml2df(path):\n",
    "    d_image = xml2dict.parse(open(path))['annotations']\n",
    "\n",
    "    data_bbox = []\n",
    "\n",
    "    for image in d_image['image']:\n",
    "        image_data = {k:image[k] for k in ['@name', '@height', '@width', '@task_id']}\n",
    "        if 'box' in image:\n",
    "            if isinstance(image['box'], dict):\n",
    "                bboxes = [image['box']]\n",
    "            elif isinstance(image['box'], list):\n",
    "                bboxes = image['box']\n",
    "            else:\n",
    "                1/0\n",
    "            for bbox in bboxes:\n",
    "                bbox.update(image_data)\n",
    "                data_bbox.append(bbox)\n",
    "        else:\n",
    "            data_bbox.append(image_data)\n",
    "    df_image = pd.DataFrame(data_bbox)    \n",
    "    return df_image\n",
    "def merge_track_image_annotations(df_track, df_image):\n",
    "    df_track['uname'] = df_track.apply(get_unique_name, 1)\n",
    "    name_count = df_track.groupby('uname').size()\n",
    "    df_track = df_track.set_index('uname')\n",
    "\n",
    "    name_count.sort_values()\n",
    "\n",
    "\n",
    "    df_image['uname'] = df_image.apply(get_unique_name, 1)\n",
    "    df_image = df_image.set_index('uname')\n",
    "\n",
    "    name_image = set(df_image.index.unique())\n",
    "    name_track = set(df_track.index.unique())\n",
    "\n",
    "    df_image = df_image.sort_index()\n",
    "    df_track = df_track.sort_index()\n",
    "\n",
    "    df_image['track_id'] = df_track['@id']\n",
    "\n",
    "    def f(row):\n",
    "        assert len(row['@label'].unique()) == 1, 'Invalid trackid {}, has more than one label per track???'.format(row.iloc[0]['track_id'])\n",
    "    df_image.groupby('track_id').apply(f)\n",
    "    return df_image\n",
    "\n",
    "df_image = load_image_xml2df('/tmp/anns.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a88b0c-280e-4b5a-8386-dc6fe0c1a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge['is_action_frame'] = df_merge['@name'].apply(lambda x: x.startswith('Action_'))\n",
    "# print(df_merge['is_action_frame'].mean())\n",
    "# df_merge[df_merge['is_action_frame']]\n",
    "def get_user(row):\n",
    "    if row['@name'].startswith('Action_'):\n",
    "        return row['@name'].split('/')[1].split('_')[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "df_image['user'] = df_image.apply(get_user, 1)\n",
    "val_users = ['hungng', 'chungtd12', 'thomp4', 'thuyhv5']\n",
    "df_image['is_val'] = df_image.user.apply(lambda x: x in val_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e206252-33ff-41bd-8d49-8e56f66f7a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images 5091\n",
      "Num images 31939\n"
     ]
    }
   ],
   "source": [
    "def to_coco_format(df):\n",
    "    image_name2id = {v:k for k, v in enumerate(df['@name'].unique())}\n",
    "    cat_name2id = {v:k for k, v in enumerate(df['@label'].unique())}\n",
    "\n",
    "    out_dict = dict(images=[], annotations=[], categories=[])\n",
    "    for _, row in df.iterrows():\n",
    "        x, y, x2, y2 = [float(row[k]) for k in ['@xtl', '@ytl', '@xbr', '@ybr']]\n",
    "        if np.isnan(x):\n",
    "            continue\n",
    "        w,h = x2-x, y2-y\n",
    "        ann = dict(id=len(out_dict['annotations']),\n",
    "                  bbox=[x,y,w,h],\n",
    "                   area=h*w,\n",
    "                   category_id=cat_name2id[row['@label']],\n",
    "                   image_id=image_name2id[row['@name']],\n",
    "                   # track_id=int(row['track_id']),\n",
    "                  )\n",
    "        out_dict['annotations'].append(ann)\n",
    "    for k, v in image_name2id.items():\n",
    "        out_dict['images'].append(dict(id=v, file_name=k))\n",
    "    for k, v in cat_name2id.items():\n",
    "        out_dict['categories'].append(dict(id=v, name=k))\n",
    "    \n",
    "\n",
    "    # cc = AvCOCO(out_dict)\n",
    "    # out_dict['images'] = cc.loadImgs(cc.imgToAnns.keys())\n",
    "    print('Num images', len(out_dict['images']))\n",
    "    return out_dict\n",
    "val_dict = to_coco_format(df_image[df_image.is_val])\n",
    "train_dict = to_coco_format(df_image[~df_image.is_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37168e3-e335-4048-bb62-71f221dca1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = 0\n",
    "count = 0\n",
    "with open('/tmp/expect_img_list.txt', 'w') as f:\n",
    "    for img in cc.img_ids:\n",
    "        img_info = cc.gt.imgs[img]\n",
    "        fn = osp.join(cc.img_dir, img_info['file_name'])\n",
    "        f.write(fn+'\\n')\n",
    "        if not osp.exists(fn) :#and not '.jpg' in fn:\n",
    "            missing_count += 1\n",
    "            \n",
    "        else:\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca2abc-2f3b-4229-8dc7-9bb01e0b19af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7802, 24137)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eab35-2a42-4758-ad1f-25c47f3caa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = CocoDataset(train_dict, '/data/cvat-raw-images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf64c3-88d6-4b5e-8f13-af93f217589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.visualize(show=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee615ea1-6e97-40ac-8473-152ed061f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b8b3e-605e-4a92-8614-386ac56c4e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

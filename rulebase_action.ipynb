{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4909d44-e2f6-45b3-b854-20b73ee709cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9dc25-1b38-4db6-8377-e1607ac9c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avcv.all import *\n",
    "import torch, torch.nn as nn\n",
    "from dms_drowsiness.video_writer import Board\n",
    "import onnxruntime\n",
    "import numpy as np, cv2\n",
    "from PIL import Image\n",
    "from ple.all import *\n",
    "import torch.utils.data as td\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eac48b-faf1-4050-bf6c-146ba92eea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label:\n",
    "    def __init__(self, label, video):\n",
    "        self.label = label\n",
    "        self.video = video\n",
    "        \n",
    "    def check_action_at_frame_idx(self, i):\n",
    "        if isinstance(i, int):\n",
    "            i = i/self.video.fps\n",
    "            \n",
    "        actions = []\n",
    "        for action in self.label['annotation']['actionAnnotationList']:\n",
    "            if i >= action['start'] and i < action['end']:\n",
    "                action_idx = action['action']\n",
    "                action_name = self.actionid2name[action_idx]\n",
    "                actions.append(action_name)\n",
    "        return actions\n",
    "    @property\n",
    "    def actionid2name(self):\n",
    "        if hasattr(self, '_actionid2name'):\n",
    "            return self._actionid2name\n",
    "        ret = dict()\n",
    "        for actionLabel in self.label['config']['actionLabelData']:\n",
    "            ret[actionLabel['id']] = actionLabel['name']\n",
    "        self._actionid2name = ret\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c17ae-0809-4d99-a90e-2ec89a966829",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_DIR_COCO ='/home/anhvth8/gitprojects/YOLOX/.cache/raw_video_predict_face_food'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136e858-8416-45a1-9633-505ad350fc86",
   "metadata": {},
   "source": [
    "## Read 2d video feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77eeffe-cb3a-4757-b855-eae0aeb39253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_flatten_to_2d_feature(flatten_sample):\n",
    "    feat_sizes = [416//8, 416//16, 416//32]\n",
    "    # reg_orig_shape = np.array(reg_orig_shape)**2\n",
    "    cur_i = 0\n",
    "    feats = []\n",
    "    for feat_size in feat_sizes:\n",
    "        a = cur_i\n",
    "        b = a+feat_size**2\n",
    "        cur_i = b\n",
    "        feats.append(flatten_sample[a:b].reshape(feat_size, feat_size, -1))\n",
    "    return feats\n",
    "\n",
    "def read_raw_feat_one_video(path):\n",
    "    data = dict(mmcv.load(path))\n",
    "    # for k in data:\n",
    "    #     data[k] = convert_flatten_to_2d_feature(data[k])\n",
    "    return data\n",
    "    # list_json_paths[0]['raw_feat_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbabd0-e1db-4584-8111-3d40093bc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_RAW_DIR_FOOD = '/data/DMS_Behavior_Detection/RawVideos/Action_Eating/'\n",
    "VIDEO_RAW_DIR_CIGARRET = '/data/DMS_Behavior_Detection/mobile_cigarret_foreignerUS'\n",
    "VAL_USERS = ['hungng', 'chungtd12', 'thomp4', 'thuyhv5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec11a1-164d-4c48-983f-86501db7d3e9",
   "metadata": {},
   "source": [
    "### get_meta_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1e312-f266-4dff-9a7a-a7443adb46b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2658537-19bb-4516-9130-e74bb2fb7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_paths = list_json_paths[0]\n",
    "cc = CocoDataset(json_paths['pred_json_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf5dcf-fff1-4253-9f13-bb1312c428db",
   "metadata": {},
   "source": [
    "### video_to_coco_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7d220-c521-4b7a-ad69-bf14558793db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All video are extracted to coco-format :D\n"
     ]
    }
   ],
   "source": [
    "def construct_cmd(video_inp, dry_run=True):\n",
    "    cmd=f\"python tools/eval_export.py -f exps/dms/mb2_face_food.py --input_video {video_inp} --out_dir .cache/raw_video_predict_face_food/ -d 1\"\n",
    "    if not dry_run:\n",
    "        os.system(cmd)\n",
    "    return cmd\n",
    "\n",
    "def video_to_coco_format(tobe_extract_videos):\n",
    "\n",
    "\n",
    "    if len(tobe_extract_videos):\n",
    "        with open('/tmp/listcmd.sh', 'w') as f:\n",
    "            for video in tobe_extract_videos:\n",
    "                cmd = construct_cmd(video)\n",
    "                f.write(cmd+'\\n')\n",
    "        !python scripts/run_list_commands.py /tmp/listcmd.sh 8 \n",
    "\n",
    "    else:\n",
    "        print('All video are extracted to coco-format :D')\n",
    "        \n",
    "video_to_coco_format(tobe_extract_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3ab01-b752-415f-b483-4bae90750a60",
   "metadata": {},
   "source": [
    "# Extract coco-format prediction of detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18c7b9-4a27-4c54-a56c-9c7f6e67518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(inp):\n",
    "    index, json_paths = inp\n",
    "    v = mmcv.VideoReader(json_paths['video_path'])\n",
    "    label = Label(mmcv.load(json_paths['label_path']), v)\n",
    "    cc = CocoDataset(json_paths['pred_json_path'])\n",
    "    data = []\n",
    "    for i in cc.img_ids:\n",
    "        actions = label.check_action_at_frame_idx(i)\n",
    "        anns = cc.gt.imgToAnns[i]\n",
    "        img = cc.gt.imgs[i]\n",
    "        img_path = osp.join(cc.img_dir, img['file_name'])\n",
    "        data.append((actions[0] if len(actions) else 'none' , index, img_path, img['id']))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69242eba-0891-47ab-b8a3-59e5e3fc9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 12:34:13.360 | INFO     | avcv.process:multi_thread:25 - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(label_paths)=67\n",
      "Collecting data from scratch\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 110/109, 10.2 task/s, elapsed: 11s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 12:34:24.198 | INFO     | avcv.process:multi_thread:34 - multi_thread collect_data, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 1.97 s, total: 14.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CACHE_DF_PATH = '/tmp/eating_cache_data_df.pkl'\n",
    "if not osp.exists(CACHE_DF_PATH) or 1:\n",
    "    list_json_paths = []\n",
    "    label_paths  = glob('/data/DMS_Behavior_Detection/RawVideos/Action_Eating/**/*.json', recursive=True)\n",
    "    for label_path in label_paths:\n",
    "        try:\n",
    "            json_paths = get_meta_jsons(label_path,)\n",
    "            list_json_paths.append(json_paths)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    label_paths  = glob('/data/DMS_Behavior_Detection/mobile_cigarret_foreignerUS/*/**/*.json', recursive=True)\n",
    "    print(f'{len(label_paths)=}')\n",
    "    for label_path in label_paths:\n",
    "        try:\n",
    "            json_paths = get_meta_jsons(label_path,)\n",
    "            list_json_paths.append(json_paths)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    len(list_json_paths)    \n",
    "    \n",
    "    \n",
    "    print('Collecting data from scratch')\n",
    "    data = multi_thread(collect_data, list(enumerate(list_json_paths)), verbose=1, pbar_iterval=10)\n",
    "    all_data = []\n",
    "    for _ in data: all_data += _\n",
    "\n",
    "    df = pd.DataFrame(all_data, columns=['action', 'video_index', 'img_path', 'img_id'])\n",
    "    #-smocking->smoking\n",
    "    ids = df[df['action'] == 'smocking'].index\n",
    "    df.loc[ids, 'action'] = 'smoking'\n",
    "    mmcv.dump(df, CACHE_DF_PATH)\n",
    "else:\n",
    "    print(f'Load data from {CACHE_DF_PATH=}')\n",
    "    df = mmcv.load(CACHE_DF_PATH)\n",
    "# df = df.set_index('img_path')\n",
    "img_path2index = dict({v:k for k, v in enumerate(sorted(df.img_path.tolist()))})\n",
    "df['img_idx'] = df['img_path'].apply(lambda path: img_path2index[path])\n",
    "df = df.set_index('img_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea73260-1441-42cf-8878-b019f101955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['username'] = df.img_path.apply(lambda x:x.split('/')[-3].split('_')[0])\n",
    "df['is_val'] = df['username'].apply(lambda x: x in VAL_USERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57b8d7-e7c1-401d-90de-7ec4239fe767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eating': 0, 'none': 1, 'mobile usage': 2, 'smoking': 3}\n"
     ]
    }
   ],
   "source": [
    "_id2action = dict(enumerate(df['action'].apply(str).unique().tolist()))\n",
    "action2id = {v:k for k, v in _id2action.items()}\n",
    "id2action = {k:v for k, v in _id2action.items()}\n",
    "print(action2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f549bee-6dc6-410d-b160-f36e32f76fa7",
   "metadata": {},
   "source": [
    "## Split train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d2823-5e3a-4ca3-ae67-fde38f70d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "catname2id = {cat['name']:cat['id'] for cat in cc.gt.cats.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb858c6-ea2a-49aa-a764-eced25325503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face': 0, 'mouth': 3, 'phone': 4, 'cigarette': 5, 'food/drink': 6, 'eye': 1}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catname2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498c08b-4705-4925-978a-c3da5a2b3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_score_ann(anns, catname):\n",
    "    cat_id = catname2id[catname]\n",
    "    anns_cat = [ann for ann in anns if ann['category_id'] == cat_id]\n",
    "    anns_cat = list(sorted(anns_cat, key=lambda x:x['score']))\n",
    "    if len(anns_cat):\n",
    "        return anns_cat[-1]\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81283949-fde3-4920-8a6c-7e0a99db9a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20f902-a142-49ed-8404-0e8f56339280",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath2index = {v:k for k,v in df['img_path'].to_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e93fa-4797-426f-b2e1-abe8a322b443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335121b2-addb-46c4-8d28-30ff08659b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['face', 'mouth', 'phone','cigarette', 'food/drink']\n",
    "for obj in objects:\n",
    "    df[obj] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb115c32-6415-4902-90b9-f3e8a90a3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['img_size'] = df.img_path.apply(lambda x:Image.open(x).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af970ac-5ada-4a9e-a566-4936e2faaeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 109/109 [01:48<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for json_paths in tqdm(list_json_paths):\n",
    "    cc = CocoDataset(json_paths['pred_json_path'])\n",
    "    for img_id in cc.img_ids:\n",
    "        img = cc.gt.imgs[img_id]\n",
    "        img_path = osp.abspath(osp.join(cc.img_dir, img['file_name']))\n",
    "        anns = cc.gt.imgToAnns[img_id]\n",
    "        index = imgpath2index[img_path]\n",
    "        for obj in objects:\n",
    "            ann = get_max_score_ann(anns, obj)\n",
    "            imw, imh = df.loc[index].img_size\n",
    "            if ann is not None:\n",
    "                x,y,w,h = ann['bbox']\n",
    "                x1,y1 = x,y\n",
    "                x2, y2 = x1+w, y1+h\n",
    "                df.loc[index, obj] = str([x1/imw,y1/imh,x2/imw,y2/imh,ann['score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad81df-4be3-4101-beb8-f2e303975f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b03ed0-7bbc-414d-a3fe-c6f908ca2607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `bops.box_iou` not found.\n"
     ]
    }
   ],
   "source": [
    "bops.box_iou??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac88291-6e4c-487c-8f43-eeb3d7fe7c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b4814-0e98-40dd-934d-dd88435c2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.ops.boxes as bops\n",
    "def xyxys2box(box):\n",
    "    if isinstance(box, str):\n",
    "        return eval(box)[:4]\n",
    "    else:\n",
    "        return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076a47e-446e-4300-98f3-b68c8b0469fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row['food/drink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d990512-665c-4086-8375-3a3c6b088a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_one_row(row):\n",
    "    img = mmcv.imread(row.img_path)\n",
    "    box_colors = [        0.000, 0.447, 0.741,\n",
    "        0.850, 0.325, 0.098,\n",
    "        0.929, 0.694, 0.125,\n",
    "        0.494, 0.184, 0.556,\n",
    "        0.466, 0.674, 0.188,\n",
    "        0.301, 0.745, 0.933,\n",
    "        0.635, 0.078, 0.184,\n",
    "        0.300, 0.300, 0.300,]\n",
    "    box_colors = np.array(box_colors).reshape(-1, 3)*255\n",
    "    box_colors = box_colors.astype(int).tolist()\n",
    "    imw, imh = row.img_size\n",
    "    \n",
    "    for i, obj in enumerate(objects):\n",
    "        if row[obj] is None: continue\n",
    "        x1,y1,x2,y2,s = eval(row[obj])\n",
    "        x1 *= imw\n",
    "        x2 *= imw\n",
    "        y1 *= imh\n",
    "        y2 *= imh\n",
    "        cls_ids = [0]\n",
    "        texts = [f'{obj} {s*100:0.2f}%']\n",
    "        bboxes = [[x1,y1,x2,y2]]\n",
    "        scores = [s]\n",
    "        img = bbox_visualize(img, bboxes, scores,cls_ids, texts=texts, box_color=box_colors[i], conf=0.0)\n",
    "\n",
    "    imshow(img, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b2c76-0f02-4988-8c57-edc5d861a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cal_iou(box1, box2):\n",
    "    box1 = xyxys2box(box1)\n",
    "    box2 = xyxys2box(box2)\n",
    "    box1 = torch.tensor([box1], dtype=torch.float)\n",
    "    box2 = torch.tensor([box2], dtype=torch.float)\n",
    "    iou = bops.generalized_box_iou(box1, box2).item()\n",
    "    return iou\n",
    "cal_iou(row.mouth, row.face, ),cal_iou(row.face, row.mouth, )\n",
    "\n",
    "def cal_bbox_overlap(bb1, bb2, over_box_2=True):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "    def to_dict(bb):\n",
    "        bb=xyxys2box(bb)\n",
    "        x1,y1,x2,y2=bb\n",
    "        return dict(x1=x1, y1=y1,x2=x2,y2=y2)\n",
    "    if bb1 is None or bb2 is None:\n",
    "        return None\n",
    "    bb1 = to_dict(bb1)\n",
    "    bb2 = to_dict(bb2)\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    if over_box_2:\n",
    "        bb = bb2\n",
    "    else:\n",
    "        bb = bb1\n",
    "        \n",
    "    area = (bb['y2']-bb['y1'])*(bb['x2']-bb['x1'])\n",
    "    return intersection_area/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1580628-218d-44ca-b1ad-cc4898e85b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "    cx1, cy1 = box1[0::2].mean(), box1[0::1].mean()\n",
    "    cx2, cy2 = box2[0::2].mean(), box2[0::1].mean()\n",
    "    distance = ((cx2-cx1)**2+(cy2-cy1)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb717f5-ba95-4e10-ba48-4eb654186719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_distance(bb1, bb2):\n",
    "    def _get_center(bb):\n",
    "        bb = xyxys2box(bb)[:4]\n",
    "        x1,y1,x2,y2 = bb\n",
    "        return (x1+x2)/2, (y1+y2)/2\n",
    "    if bb1 is None or bb2 is None: return None\n",
    "\n",
    "    cx1, cy1 = _get_center(bb1)\n",
    "    cx2, cy2 = _get_center(bb2)\n",
    "    return np.sqrt((cx2-cx1)**2+(cy2-cy1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a08df-ed92-45c6-88a3-c136cee709c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iou_face_food'] = df.apply(lambda row:cal_bbox_overlap(row['face'], row['food/drink']), 1)\n",
    "df['iou_face_cigarette'] = df.apply(lambda row:cal_bbox_overlap(row['face'], row['cigarette']), 1)\n",
    "df['iou_face_phone'] = df.apply(lambda row:cal_bbox_overlap(row['face'], row['phone']), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8399f-850a-4e2b-9c02-cff19d75cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_face_food'] = df.apply(lambda row:bbox_distance(row['face'], row['food/drink']), 1)\n",
    "df['distance_face_cigarette'] = df.apply(lambda row:bbox_distance(row['face'], row['cigarette']), 1)\n",
    "df['distance_face_phone'] = df.apply(lambda row:bbox_distance(row['face'], row['phone']), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a63ed-2c10-4319-8216-2b32418d81fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(bb):\n",
    "    if bb is None:return bb\n",
    "    s = eval(bb)[-1]\n",
    "    return s\n",
    "df['food_score'] = df.apply(lambda row: get_score(row['food/drink']), 1)\n",
    "df['cigarette_score'] = df.apply(lambda row: get_score(row['cigarette']), 1)\n",
    "df['phone_score'] = df.apply(lambda row: get_score(row['phone']), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18af769-6d3f-4200-910b-f4257fba0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import tree\n",
    "def construct_x(row, FEATURE_NAMES):\n",
    "    data = []\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        value = row[feature_name]\n",
    "        if np.isnan(value):\n",
    "            if 'distance' in feature_name:\n",
    "                value = 10\n",
    "            elif 'score' in feature_name:\n",
    "                value = 0\n",
    "        if 'score' in feature_name:\n",
    "            if value < 0.3:\n",
    "                value = 0\n",
    "        data.append(value)\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3758a-9072-4a81-82db-f06bf7388e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FEATURE_NAMES=['iou_face_food', 'iou_face_cigarette', 'iou_face_phone', 'distance_face_food', 'distance_face_cigarette', 'distance_face_phone', 'food_score', 'cigarette_score', 'phone_score']\n",
    "def get_features_names(object_name):\n",
    "    \n",
    "    FEATURE_NAMES = [_ for _ in ALL_FEATURE_NAMES if object_name in _ and not 'iou' in _]\n",
    "    return FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0897791-5917-4a8b-85f7-1e119c9eaf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_DEPTH = 2\n",
    "def build_tree_cls(object_name='phone', class_name='mobile usage'):\n",
    "    FEATURE_NAMES = get_features_names(object_name)\n",
    "    print(f'{FEATURE_NAMES=}, {class_name=}')\n",
    "    def sample_data_frames(df, class_name):\n",
    "        df = df.copy()\n",
    "        df_positive = df[df['action'] == class_name]\n",
    "        df_negative = df[df['action'] != class_name].sample(len(df_positive))\n",
    "        df_negative['action'] = 'unknown'\n",
    "        _df = pd.concat([df_positive, df_negative])\n",
    "\n",
    "        _df['X'] = df.apply(lambda x:construct_x(x, FEATURE_NAMES), 1)\n",
    "\n",
    "        X = np.array(_df.X.values.tolist())\n",
    "        y = np.array(_df['action'].tolist())\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    X,y = sample_data_frames(df, class_name)\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=MAX_DEPTH)\n",
    "    clf = clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7dbdd4-594c-4ee7-9a08-49801daaee06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56bc0b-4fe9-40aa-a3ef-0f2063a7879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, object_name, class_name):\n",
    "    clf = clfs[class_name]\n",
    "    FEATURE_NAMES = get_features_names(object_name)\n",
    "    print(f'{FEATURE_NAMES=}, {class_name=}')\n",
    "    \n",
    "    df['X'] = df.apply(lambda x:construct_x(x, FEATURE_NAMES), 1)\n",
    "\n",
    "    X = np.array(df.X.values.tolist())\n",
    "    return clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4841ad-af86-4963-83ab-eb2db115350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE_NAMES=['distance_face_phone', 'phone_score'], class_name='mobile usage'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvth8/.conda/envs/py38/lib/python3.8/site-packages/sklearn/tree/tree.py:149: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__cinit__() takes exactly 5 positional arguments (6 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [564]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clfs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m object_name, class_name \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobile usage\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfood\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meating\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcigarette\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoking\u001b[39m\u001b[38;5;124m'\u001b[39m)]:\n\u001b[0;32m----> 3\u001b[0m     clfs[class_name] \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_tree_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [562]\u001b[0m, in \u001b[0;36mbuild_tree_cls\u001b[0;34m(object_name, class_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m X,y \u001b[38;5;241m=\u001b[39m sample_data_frames(df, class_name)\n\u001b[1;32m     20\u001b[0m clf \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mDecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39mMAX_DEPTH)\n\u001b[0;32m---> 21\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clf\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/tree/tree.py:797\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    762\u001b[0m         X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;124;03m    self : object\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/sklearn/tree/tree.py:340\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    338\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter, Splitter):\n\u001b[0;32m--> 340\u001b[0m     splitter \u001b[38;5;241m=\u001b[39m \u001b[43mSPLITTERS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_features_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmin_samples_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmin_weight_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_ \u001b[38;5;241m=\u001b[39m Tree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\u001b[39;00m\n",
      "File \u001b[0;32msklearn/tree/_splitter.pyx:54\u001b[0m, in \u001b[0;36msklearn.tree._splitter.Splitter.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __cinit__() takes exactly 5 positional arguments (6 given)"
     ]
    }
   ],
   "source": [
    "clfs = {}\n",
    "for object_name, class_name in [('phone', 'mobile usage'), ('food', 'eating'), ('cigarette', 'smoking')]:\n",
    "    clfs[class_name] = build_tree_cls(object_name, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0097aef-5b5a-43f3-9a1f-facc484831f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_pred_mobile_usage'] = predict(df, 'phone', 'mobile usage')\n",
    "df['y_pred_eating'] = predict(df, 'food', 'eating')\n",
    "df['y_pred_smoking'] = predict(df, 'cigarette', 'smoking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d6cff-32f6-4e37-999a-0ecf2e3d3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.action=='eating']['distance_face_food'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10b8e7-1286-4f20-9c4e-06313e748f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "row.phone_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a569fad-85a6-486f-90c4-330249ca49bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969cc2d1-c5f2-4440-8259-215c1555371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df[df.action=='eating'].iloc[0]\n",
    "\n",
    "def is_eating(row, score_thr=0.3, dist=0.5):\n",
    "    if np.isnan(row.food_score) or np.isnan(row.food_score):return False\n",
    "        \n",
    "    if row.food_score > score_thr and row.distance_face_food < dist:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_using_phone(row, score_thr=0.3, dist=0.5):\n",
    "    if np.isnan(row.phone_score) or np.isnan(row.distance_face_phone):\n",
    "        return False\n",
    "    if row.phone_score > score_thr and row.distance_face_phone < dist:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_smoking(row, score_thr=0.3, dist=0.5):\n",
    "    if np.isnan(row.cigarette_score) or np.isnan(row.distance_face_cigarette):\n",
    "        return False\n",
    "    if row.cigarette_score > score_thr and row.distance_face_cigarette < dist:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def predict_rule(row):\n",
    "    rt = []\n",
    "    if is_eating(row):\n",
    "        rt.append('eating')\n",
    "        \n",
    "    if is_using_phone(row):\n",
    "        rt.append('mobile usage')\n",
    "        \n",
    "    if is_smoking(row):\n",
    "        rt.append('smoking')\n",
    "        \n",
    "    return rt\n",
    "df['action_pred'] = df.apply(predict_rule, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64199819-7ff2-46a4-afd0-be65811ea580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one_row(row):\n",
    "    img = mmcv.imread(row.img_path)\n",
    "    box_colors = [        0.000, 0.447, 0.741,\n",
    "        0.850, 0.325, 0.098,\n",
    "        0.929, 0.694, 0.125,\n",
    "        0.494, 0.184, 0.556,\n",
    "        0.466, 0.674, 0.188,\n",
    "        0.301, 0.745, 0.933,\n",
    "        0.635, 0.078, 0.184,\n",
    "        0.300, 0.300, 0.300,]\n",
    "    box_colors = np.array(box_colors).reshape(-1, 3)*255\n",
    "    box_colors = box_colors.astype(int).tolist()\n",
    "    imw, imh = row.img_size\n",
    "    \n",
    "    for i, obj in enumerate(objects):\n",
    "        if row[obj] is None: continue\n",
    "        x1,y1,x2,y2,s = eval(row[obj])\n",
    "        x1 *= imw\n",
    "        x2 *= imw\n",
    "        y1 *= imh\n",
    "        y2 *= imh\n",
    "        cls_ids = [0]\n",
    "        texts = [f'{obj} {s*100:0.2f}%']\n",
    "        bboxes = [[x1,y1,x2,y2]]\n",
    "        scores = [s]\n",
    "        img = bbox_visualize(img, bboxes, scores,cls_ids, texts=texts, box_color=box_colors[i], conf=0.0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc162823-6aee-4731-9951-1469d26d6b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eating']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rule(df.loc[82553])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2fb5f4-317f-4371-bf61-949c58a080a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _df = df[df.video_index==32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61f745-e429-4a48-b597-dcf76cd659bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3d081-7587-4481-9a5d-de64331b5bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▌                                                           | 214/2132 [00:01<00:10, 184.62it/s]\n",
      "2022-09-28 16:32:14.603 | INFO     | avcv.utils:images_to_video:267 - Write video, output_size: (700, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 214/214, 261.0 task/s, elapsed: 1s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 16:32:15.425 | INFO     | avcv.utils:images_to_video:277 - -> /home/anhvth8/gitprojects/YOLOX/vis.mp4\n"
     ]
    }
   ],
   "source": [
    "list_vis = []\n",
    "for _, row in tqdm(_df[0::10].iterrows(), total=len(_df)):\n",
    "    vis = draw_one_row(row)\n",
    "    board = Board(10, line_w=600)\n",
    "    # for i, action in enumerate(row.action_pred):\n",
    "    i = 1\n",
    "    board.set_line_text(0, ' '.join(row.action_pred)+f' | {row.name}')\n",
    "    \n",
    "    \n",
    "    for feat_name in ALL_FEATURE_NAMES:\n",
    "        val = row[feat_name]\n",
    "        if not np.isnan(val):\n",
    "            board.set_line_text(i, f'{feat_name}:{val:0.2f}')\n",
    "            i+=1\n",
    "    list_vis += [board.img_concat(vis)]    \n",
    "images_to_video(list_vis, 'vis.mp4', output_size=(700, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442ef54-0ae1-4a9d-97e3-ab04b0ea0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.json  pred_mb2_face_food.json  pred_mb2_face_food_raw_outputs.pkl\n"
     ]
    }
   ],
   "source": [
    "ls .cache/raw_video_predict_face_food/vietph_Sensing_Session2_CAMc_1b_2c_3a_4d_5b_6b_7b_8a_9a_10a_11b_12b_13b_14b_15b_16f_17a_18a_19a_20b/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c6e3b-723a-4f0c-9f0b-2fbf2ff14ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = CocoDataset('.cache/raw_video_predict_face_food/vietph_Sensing_Session2_CAMc_1b_2c_3a_4d_5b_6b_7b_8a_9a_10a_11b_12b_13b_14b_15b_16f_17a_18a_19a_20b/annotations/pred_mb2_face_food.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e284b-0d11-4795-97da-65ed5971c5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action                                                                  none\n",
       "video_index                                                               32\n",
       "img_path                   /home/anhvth8/gitprojects/YOLOX/.cache/raw_vid...\n",
       "img_id                                                                  2130\n",
       "username                                                              tunm13\n",
       "is_val                                                                 False\n",
       "face                       [0.3469236195087433, 0.2684265772501628, 0.558...\n",
       "mouth                      [0.4113991856575012, 0.6045654084947374, 0.488...\n",
       "phone                                                                   None\n",
       "cigarette                                                               None\n",
       "food/drink                                                              None\n",
       "img_size                                                          (512, 288)\n",
       "iou_face_food                                                            NaN\n",
       "distance_face_food                                                       NaN\n",
       "distance_face_cigarret                                                   NaN\n",
       "iou_face_cigarette                                                       NaN\n",
       "distance_face_cigarette                                                  NaN\n",
       "distance_face_phone                                                      NaN\n",
       "iou_face_phone                                                           NaN\n",
       "food_score                                                               NaN\n",
       "cigarette_score                                                          NaN\n",
       "phone_score                                                              NaN\n",
       "X                                                                    [10, 0]\n",
       "y_pred_mobile_usage                                                  unknown\n",
       "y_pred_eating                                                        unknown\n",
       "y_pred_smoking                                                       unknown\n",
       "action_pred                                                               []\n",
       "Name: 84473, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e721479-0cab-4366-9b9e-8c46377cf29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face', 'mouth', 'phone', 'cigarette', 'food/drink']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d7be5-7dca-48b2-96ef-cf56b08fccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 4920/4920 [00:03<00:00, 1410.86it/s]\n"
     ]
    }
   ],
   "source": [
    "list_data = []\n",
    "for img_id in tqdm(cc.img_ids[0::10]):\n",
    "    data = dict()\n",
    "    img = cc.gt.imgs[img_id]\n",
    "    img_path = osp.abspath(osp.join(cc.img_dir, img['file_name']))\n",
    "    anns = cc.gt.imgToAnns[img_id]\n",
    "    data['img_path'] = img_path\n",
    "    # index = imgpath2index[img_path]\n",
    "    \n",
    "    for obj in objects:\n",
    "        ann = get_max_score_ann(anns, obj)\n",
    "        # imw, imh = df.loc[index].img_size\n",
    "        data['img_size'] = imw, imh = Image.open(img_path).size\n",
    "        if ann is not None:\n",
    "            x,y,w,h = ann['bbox']\n",
    "            x1,y1 = x,y\n",
    "            x2, y2 = x1+w, y1+h\n",
    "            data[obj] = str([x1/imw,y1/imh,x2/imw,y2/imh,ann['score']])\n",
    "            data[f'{obj}_score'] = ann['score']\n",
    "    list_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c25093-02ca-4763-9a13-2480bab7f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e03bd-1521-4fe0-a463-a818dba054c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_distance(bb1, bb2):\n",
    "    try:\n",
    "        def _get_center(bb):\n",
    "            bb = xyxys2box(bb)[:4]\n",
    "            x1,y1,x2,y2 = bb\n",
    "            return (x1+x2)/2, (y1+y2)/2\n",
    "        if bb1 is None or bb2 is None: return None\n",
    "        cx1, cy1 = _get_center(bb1)\n",
    "        cx2, cy2 = _get_center(bb2)\n",
    "        return np.sqrt((cx2-cx1)**2+(cy2-cy1)**2)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f5e22-3ea5-4dad-86d5-5ea762357dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_face_food'] = df.apply(lambda row:bbox_distance(row['face'], row['food/drink']), 1)\n",
    "df['distance_face_cigarette'] = df.apply(lambda row:bbox_distance(row['face'], row['cigarette']), 1)\n",
    "df['distance_face_phone'] = df.apply(lambda row:bbox_distance(row['face'], row['phone']), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a14d6-97fb-466a-bfd6-c19d4757831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_eating(row, score_thr=0.3, dist=0.5):\n",
    "    if np.isnan(row['food/drink_score']) or np.isnan(row.distance_face_food):return False\n",
    "    if row['food/drink_score'] > score_thr and row.distance_face_food < dist:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_using_phone(row, score_thr=0.3, dist=0.5):\n",
    "    if np.isnan(row.phone_score) or np.isnan(row.distance_face_phone):\n",
    "        return False\n",
    "    if row.phone_score > score_thr and row.distance_face_phone < dist:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_smoking(row, score_thr=0.3, dist=0.5):\n",
    "    if np.isnan(row.cigarette_score) or np.isnan(row.distance_face_cigarette):\n",
    "        return False\n",
    "    if row.cigarette_score > score_thr and row.distance_face_cigarette < dist:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def predict_rule(row):\n",
    "    rt = []\n",
    "    if is_eating(row):\n",
    "        rt.append('eating')\n",
    "        \n",
    "    if is_using_phone(row):\n",
    "        rt.append('mobile usage')\n",
    "        \n",
    "    if is_smoking(row):\n",
    "        rt.append('smoking')\n",
    "        \n",
    "    return rt\n",
    "df['action_pred'] = df.apply(predict_rule, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb188f7a-40c6-430d-bd34-70866190be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_one_row(row):\n",
    "    img = mmcv.imread(row.img_path)\n",
    "    box_colors = [        0.000, 0.447, 0.741,\n",
    "        0.850, 0.325, 0.098,\n",
    "        0.929, 0.694, 0.125,\n",
    "        0.494, 0.184, 0.556,\n",
    "        0.466, 0.674, 0.188,\n",
    "        0.301, 0.745, 0.933,\n",
    "        0.635, 0.078, 0.184,\n",
    "        0.300, 0.300, 0.300,]\n",
    "    box_colors = np.array(box_colors).reshape(-1, 3)*255\n",
    "    box_colors = box_colors.astype(int).tolist()\n",
    "    imw, imh = row.img_size\n",
    "    \n",
    "    for i, obj in enumerate(objects):\n",
    "        if not isinstance(row[obj], str): continue\n",
    "        x1,y1,x2,y2,s = eval(row[obj])\n",
    "        x1 *= imw\n",
    "        x2 *= imw\n",
    "        y1 *= imh\n",
    "        y2 *= imh\n",
    "        cls_ids = [0]\n",
    "        texts = [f'{obj} {s*100:0.2f}%']\n",
    "        bboxes = [[x1,y1,x2,y2]]\n",
    "        scores = [s]\n",
    "        img = bbox_visualize(img, bboxes, scores,cls_ids, texts=texts, box_color=box_colors[i], conf=0.0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc3e3e-da00-45a5-b6d0-b7a8f666113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 4920/4920 [00:26<00:00, 184.48it/s]\n",
      "2022-09-28 16:49:40.781 | INFO     | avcv.utils:images_to_video:267 - Write video, output_size: (700, 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 4920/4920, 306.5 task/s, elapsed: 16s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 16:49:56.846 | INFO     | avcv.utils:images_to_video:277 - -> /home/anhvth8/gitprojects/YOLOX/vis.mp4\n"
     ]
    }
   ],
   "source": [
    "list_vis = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    vis = draw_one_row(row)\n",
    "    board = Board(10, line_w=600)\n",
    "    # for i, action in enumerate(row.action_pred):\n",
    "    i = 1\n",
    "    board.set_line_text(0, ' '.join(row.action_pred)+f' | {row.name}')\n",
    "    \n",
    "    \n",
    "    for feat_name in ALL_FEATURE_NAMES:\n",
    "        try:\n",
    "            val = row[feat_name]\n",
    "            if not np.isnan(val):\n",
    "                board.set_line_text(i, f'{feat_name}:{val:0.2f}')\n",
    "                i+=1\n",
    "        except:pass\n",
    "    list_vis += [board.img_concat(vis)]    \n",
    "images_to_video(list_vis, 'vis.mp4', output_size=(700, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38543a64-7996-4703-8a8e-aefff5e05f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de1573-459f-42f5-849f-40ef870c2ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515da3a-0fa8-4e9f-9e7b-3e5970c9ab47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f2449-cd76-4bfa-977a-ecd72da33d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33227680-76a5-40fa-96bc-717283e2f9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
